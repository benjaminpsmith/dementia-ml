{"cells":[{"cell_type":"code","execution_count":119,"metadata":{"id":"9c0qcOtitB49","outputId":"d08dbcf9-499e-43fa-c632-6d70694bc8c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device used: cpu\n"]},{"data":{"text/plain":["False"]},"execution_count":119,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torch.nn.functional as F\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Device used: {device.type}')\n","\n","torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{"id":"qNm0SENHtB4-"},"source":["# Hyperparameters for project"]},{"cell_type":"code","execution_count":120,"metadata":{"id":"CMd_o2ZAtB4_"},"outputs":[],"source":["train_size = 0.7\n","test_size = 1 - train_size\n","num_epochs = 5\n","batch_size = 4\n","learning_rate = 0.001"]},{"cell_type":"markdown","metadata":{"id":"ZT1StiSMtB4_"},"source":["# Data preprocessing\n"]},{"cell_type":"markdown","metadata":{"id":"e5v1CY5EtB4_"},"source":["## Import the dataset\n","Dataset should be imported as a pytorch dataloader for batch optimization"]},{"cell_type":"markdown","metadata":{},"source":["Custom Dataset"]},{"cell_type":"markdown","metadata":{},"source":["## **Data augmentation**\n","\n","To augment the data before training, we will attempt to use two methods:\n","\n","\n","1.   Scaling\n","> Scaling is used because we wish to taken into account the varying structure size of tumors and skulls in the images.\n","\n","2.   Noise Injection\n","> Noise injection is used to help assist the model in learning the complex patterns around the tumors and make it more robust to small changes in the data.\n","> We will experiment with both Gaussian (random), and salt-and-paper (random values to min. or max. values, 0 to 255) noise injection.\n","\n","All combinations of these will be used to determine their effectiveness, and if they introduce any *bias*, *artifacts*, or *overfitting* both in isolation, or combination.\n","\n","The order of the data augmentation will be:\n","1.   No Data Augmentation\n","2.   Scaling\n","3.   Noise Injection\n","4.   Scaling, Noise Injection"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["from torchvision.transforms import v2\n","\n","def add_noise_gaussian(tensor, mean = 0, std = 0.05):\n","    \"\"\"\n","    Parameters:\n","    - tensor: PyTorch tensor data type without noise (input)\n","    - mean: Mean of the Gaussian distribution\n","    - std: Standard deviation of the Gaussian distribution\n","\n","    Returns:\n","    - tensor + noise: PyTorch tensor data type with noise (output)\n","    \"\"\"\n","    noise = torch.randn(tensor.size()) * std + mean\n","    return tensor + noise\n","\n","def add_noise_salt_pepper(tensor, salt_prob = 0.02, pepper_prob = 0.02):\n","    \"\"\"\n","    Parameters:\n","    - tensor: PyTorch tensor data type without noise (input)\n","    - salt_prob: Probability that salt noise is added (full white)\n","    - pepper_prob: Probability that pepper noise is added (full black)\n","\n","    Returns:\n","    - tensor + salt_mask = pepper_mask: PyTorch tensor data type with noise (output)\n","    that ensured to be between 0 and 1\n","    \"\"\"\n","\n","    salt_mask = (torch.rand_like(tensor) < salt_prob).float()\n","    pepper_mask = (torch.rand_like(tensor) < pepper_prob).float()\n","\n","    return torch.clamp((tensor + salt_mask - pepper_mask), 0, 1)\n","\n","# Abitrary values (set to double of base image height*width)\n","resize_x = 256\n","resize_y = 256\n","\n","# Set resize_x and resize_y before using these transforms\n","# All transforms convert it to a tensor with the dimensions of (Channels, Height, Width)\n","transforms = {\n","    'none': v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True)\n","                        ]),\n","    'scale': v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True),\n","                        v2.Resize((resize_x, resize_y), antialias=True)\n","                        ]),\n","    'noise_gaussian': v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True),\n","                        v2.Lambda(lambda x: add_noise_gaussian(x))\n","                        ]),\n","    'noise_salt_pepper': v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True),\n","                        v2.Lambda(lambda x: add_noise_salt_pepper(x))\n","                        ]),\n","    'all_gaussian':     v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True),\n","                        v2.Resize((resize_x, resize_y), antialias=True),\n","                        v2.Lambda(lambda x: add_noise_gaussian(x))\n","                        ]),\n","    'all_salt_pepper':  v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True),\n","                        v2.Resize((resize_x, resize_y), antialias=True),\n","                        v2.Lambda(lambda x: add_noise_salt_pepper(x))\n","                        ])\n","}"]},{"cell_type":"code","execution_count":122,"metadata":{},"outputs":[],"source":["from torch.utils.data import Dataset\n","from torchvision.transforms import v2\n","from PIL import Image\n","import os\n","\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.class_folders = os.listdir(root_dir)\n","        self.class_to_idx = {class_folder: i for i, class_folder in enumerate(self.class_folders)}\n","        self.images = self.make_dataset()\n","\n","    def make_dataset(self):\n","        images = []\n","        for class_folder in self.class_folders:\n","            class_path = os.path.join(self.root_dir, class_folder)\n","            for img_name in os.listdir(class_path):\n","                img_path = os.path.join(class_path, img_name)\n","                images.append((img_path, self.class_to_idx[class_folder]))\n","        return images\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.images[idx]\n","        image = Image.open(img_path)\n","\n","        random_number = np.random.uniform(0, 1)\n","\n","        # if self.transform:\n","        #     image = self.apply_random_transform(image, random_number)\n","        image = transforms['none'](image)\n","\n","        return image, label\n","    \n","    def apply_random_transform(self, image, random_number):\n","        # Example: Apply different transformations based on the random number\n","        if random_number < 0.25:\n","            return transforms['noise_gaussian'](image)\n","        elif random_number < 0.5:\n","            return transforms['noise_salt_pepper'](image)\n","        else:\n","            return transforms['none'](image)\n","    "]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","transform = v2.Compose([\n","    v2.ToImage(), \n","    v2.ToDtype(torch.float32, scale=True)\n","])\n","\n","dataset = CustomDataset(root_dir='Dataset', transform=transform)\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_size = 0.8  # You can adjust the ratio based on your needs\n","test_size = 1 - train_size\n","batch_size = 16    # Adjust according to your needs\n","\n","# Assuming your dataset is a list or any data structure that can be split\n","train_dataset, test_dataset = train_test_split(dataset, test_size=test_size, random_state=42)\n","\n","# Create DataLoader for training and testing\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"aB5UrJN0tB5D"},"source":["## Data normalization"]},{"cell_type":"markdown","metadata":{"id":"NciOQE4FtB5D"},"source":["# Architecture of the network"]},{"cell_type":"markdown","metadata":{},"source":["**CNN Model Creation**"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[],"source":["class CustomCNN(nn.Module):\n","    def __init__(self, weights=\"DEFAULT\"):\n","        super(CustomCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  # MRI images are grayscale, so in_channels=1\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.fc1 = nn.Linear(128 * 16 * 16, 256)  # Adjust for the flattened conv3 output\n","        self.fc2 = nn.Linear(256, 4)  # 4 classes in our dataset\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = x.view(-1, 128 * 16 * 16)  # Flatten the tensor for the fully connected layer\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (fc1): Linear(in_features=32768, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=4, bias=True)\n",")"]},"execution_count":126,"metadata":{},"output_type":"execute_result"}],"source":["model = CustomCNN()\n","\n","model"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[],"source":["from torch.optim import Adam, SGD\n","from torch.optim.lr_scheduler import StepLR\n","\n","def select_optimizer(optimizer_name, parameters, lr=1e-3, weight_decay=0.):\n","    if optimizer_name == \"sgd\":\n","        return torch.optim.SGD(parameters, lr=lr, weight_decay=weight_decay, momentum=0.9)\n","    elif optimizer_name == \"rmsprop\":\n","        return torch.optim.RMSprop(parameters, lr=lr, weight_decay=weight_decay, alpha=0.99)\n","    elif optimizer_name == \"adam\":\n","        return torch.optim.Adam(parameters, lr=lr, weight_decay=weight_decay)\n","    else:\n","        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n","\n","\n","# Choose optimizer and regularization hyperparameters\n","optimizer_name = \"adam\"   # Could be \"sgd\", \"rmsprop\", or \"adam\"\n","learning_rate = 0.001\n","weight_decay = 0.0\n","\n","optimizer = select_optimizer(optimizer_name=optimizer_name, parameters=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","scheduler = StepLR(optimizer, step_size=1, gamma=0.7)"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[],"source":["def train(model, device, train_loader, optimizer, scheduler, epoch):\n","    # Set the model in \"training\" mode, enabling features like dropout and\n","    # batch normalization that are specific to training.\n","    model.train()\n","\n","    # We iterate over `train_loader`, which batches the training data.\n","    # `enumerate(train_loader)` gives us a counter `batch_idx` and the data in data and target labels in target.\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        # Move our data and labels to the device we are using (CPU or GPU),\n","        # enabling accelerated computation.\n","        data, target = data.to(device), target.to(device)\n","\n","        # Clear old gradients; if not cleared, they would accumulate with subsequent backward passes.\n","        optimizer.zero_grad()\n","\n","        output = model(data)  # Forward pass to get predictions.\n","        loss = F.cross_entropy(output, target)\n","        loss.backward()       # Backpropagation to compute the gradients.\n","\n","        # Update the weights of the model based on the gradients calculated during backpropagation.\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            current_lr = scheduler.get_last_lr()[0]  # Access the last learning rate\n","            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} \"\n","                  f\"({100. * batch_idx / len(train_loader):.0f}%)]\\t\"\n","                  f\"Loss: {loss.item():.6f} (LR: {current_lr:.6f})\")\n","\n","    # Update the learning rate according to the specified schedule\n","    scheduler.step()"]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[],"source":["def test(model, device, test_loader):\n","    # Set the model to \"evaluation\" mode. This is necessary because certain layers\n","    # like dropout layers behave differently during training than during testing.\n","    model.eval()\n","\n","    test_loss = 0\n","    correct = 0\n","\n","    # Context manager under which all the operations will have `requires_grad=False`,\n","    # meaning that PyTorch will not calculate or keep track of gradients.\n","    # This is used because gradient computation is not needed for evaluation and saves memory and computation.\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","\n","            # The loss is summed up across all batches.\n","            # The reduction=\"sum\" parameter ensures that the losses are added together.\n","            test_loss += F.cross_entropy(output, target, reduction=\"sum\").item()\n","\n","            # Get the index of the max log-probability\n","            pred = output.argmax(dim=1)\n","            correct += pred.eq(target).sum().item()\n","\n","    # Total loss is divided by the number of items in the dataset to get the average loss.\n","    test_loss /= len(test_loader.dataset)\n","    # Accuracy is calculated as the percentage of correct predictions over the total number of predictions.\n","    accuracy = 100. * correct / len(test_loader.dataset)\n","\n","    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n\")"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device.\n","\n","Train Epoch: 1 [0/5120 (0%)]\tLoss: 1.400377 (LR: 0.001000)\n","Train Epoch: 1 [1600/5120 (31%)]\tLoss: 0.841064 (LR: 0.001000)\n","Train Epoch: 1 [3200/5120 (62%)]\tLoss: 1.227140 (LR: 0.001000)\n","Train Epoch: 1 [4800/5120 (94%)]\tLoss: 1.107511 (LR: 0.001000)\n","\n","Test set: Average loss: 0.9549, Accuracy: 696/1280 (54%)\n","\n","Train Epoch: 2 [0/5120 (0%)]\tLoss: 1.086693 (LR: 0.000700)\n","Train Epoch: 2 [1600/5120 (31%)]\tLoss: 0.731400 (LR: 0.000700)\n","Train Epoch: 2 [3200/5120 (62%)]\tLoss: 0.897253 (LR: 0.000700)\n","Train Epoch: 2 [4800/5120 (94%)]\tLoss: 0.661364 (LR: 0.000700)\n","\n","Test set: Average loss: 0.7689, Accuracy: 820/1280 (64%)\n","\n","Train Epoch: 3 [0/5120 (0%)]\tLoss: 0.682647 (LR: 0.000490)\n","Train Epoch: 3 [1600/5120 (31%)]\tLoss: 0.450650 (LR: 0.000490)\n","Train Epoch: 3 [3200/5120 (62%)]\tLoss: 0.427601 (LR: 0.000490)\n","Train Epoch: 3 [4800/5120 (94%)]\tLoss: 0.743272 (LR: 0.000490)\n","\n","Test set: Average loss: 0.6579, Accuracy: 922/1280 (72%)\n","\n","Train Epoch: 4 [0/5120 (0%)]\tLoss: 0.844691 (LR: 0.000343)\n","Train Epoch: 4 [1600/5120 (31%)]\tLoss: 0.558038 (LR: 0.000343)\n","Train Epoch: 4 [3200/5120 (62%)]\tLoss: 0.627026 (LR: 0.000343)\n","Train Epoch: 4 [4800/5120 (94%)]\tLoss: 0.170154 (LR: 0.000343)\n","\n","Test set: Average loss: 0.4543, Accuracy: 1033/1280 (81%)\n","\n","Train Epoch: 5 [0/5120 (0%)]\tLoss: 0.239169 (LR: 0.000240)\n","Train Epoch: 5 [1600/5120 (31%)]\tLoss: 0.170108 (LR: 0.000240)\n","Train Epoch: 5 [3200/5120 (62%)]\tLoss: 0.119290 (LR: 0.000240)\n","Train Epoch: 5 [4800/5120 (94%)]\tLoss: 0.220357 (LR: 0.000240)\n","\n","Test set: Average loss: 0.3120, Accuracy: 1121/1280 (88%)\n","\n"]}],"source":["epochs = 5\n","\n","# Determine if a GPU with CUDA support is available and use it; otherwise, use the CPU.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","print(f\"Using {device} device.\\n\")\n","\n","# Begin the training process\n","for epoch in range(1, epochs + 1):\n","    # Train the model for one epoch: go through all batches in the training dataset.\n","    train(model, device, train_loader, optimizer, scheduler, epoch)\n","\n","    # After each epoch, evaluate the model on the test dataset to monitor its performance.\n","    test(model, device, test_loader)"]}],"metadata":{"colab":{"collapsed_sections":["qNm0SENHtB4-"],"provenance":[]},"kernelspec":{"display_name":"ba-thesis","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
