{"cells":[{"cell_type":"code","execution_count":66,"metadata":{"id":"9c0qcOtitB49","outputId":"d08dbcf9-499e-43fa-c632-6d70694bc8c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device used: cpu\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torch.nn.functional as F\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Device used: {device.type}')"]},{"cell_type":"markdown","metadata":{"id":"qNm0SENHtB4-"},"source":["# Hyperparameters for project"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"CMd_o2ZAtB4_"},"outputs":[],"source":["train_size = 0.7\n","test_size = 1 - train_size\n","num_epochs = 5\n","batch_size = 4\n","learning_rate = 0.001"]},{"cell_type":"markdown","metadata":{"id":"ZT1StiSMtB4_"},"source":["# Data preprocessing\n"]},{"cell_type":"markdown","metadata":{"id":"e5v1CY5EtB4_"},"source":["## Import the dataset\n","Dataset should be imported as a pytorch dataloader for batch optimization"]},{"cell_type":"markdown","metadata":{},"source":["Custom Dataset"]},{"cell_type":"markdown","metadata":{},"source":["## **Data augmentation**\n","\n","To augment the data before training, we will attempt to use two methods:\n","\n","\n","1.   Scaling\n","> Scaling is used because we wish to taken into account the varying structure size of tumors and skulls in the images.\n","\n","2.   Noise Injection\n","> Noise injection is used to help assist the model in learning the complex patterns around the tumors and make it more robust to small changes in the data.\n","> We will experiment with both Gaussian (random), and salt-and-paper (random values to min. or max. values, 0 to 255) noise injection.\n","\n","All combinations of these will be used to determine their effectiveness, and if they introduce any *bias*, *artifacts*, or *overfitting* both in isolation, or combination.\n","\n","The order of the data augmentation will be:\n","1.   No Data Augmentation\n","2.   Scaling\n","3.   Noise Injection\n","4.   Scaling, Noise Injection"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["from torchvision.transforms import v2\n","\n","def add_noise_gaussian(tensor, mean = 0, std = 0.05):\n","    \"\"\"\n","    Parameters:\n","    - tensor: PyTorch tensor data type without noise (input)\n","    - mean: Mean of the Gaussian distribution\n","    - std: Standard deviation of the Gaussian distribution\n","\n","    Returns:\n","    - tensor + noise: PyTorch tensor data type with noise (output)\n","    \"\"\"\n","    noise = torch.randn(tensor.size()) * std + mean\n","    return tensor + noise\n","\n","def add_noise_salt_pepper(tensor, salt_prob = 0.02, pepper_prob = 0.02):\n","    \"\"\"\n","    Parameters:\n","    - tensor: PyTorch tensor data type without noise (input)\n","    - salt_prob: Probability that salt noise is added (full white)\n","    - pepper_prob: Probability that pepper noise is added (full black)\n","\n","    Returns:\n","    - tensor + salt_mask = pepper_mask: PyTorch tensor data type with noise (output)\n","    that ensured to be between 0 and 1\n","    \"\"\"\n","\n","    salt_mask = (torch.rand_like(tensor) < salt_prob).float()\n","    pepper_mask = (torch.rand_like(tensor) < pepper_prob).float()\n","\n","    return torch.clamp((tensor + salt_mask - pepper_mask), 0, 1)\n","\n","# Abitrary values (set to double of base image height*width)\n","resize_x = 256\n","resize_y = 256\n","\n","# Set resize_x and resize_y before using these transforms\n","# All transforms convert it to a tensor with the dimensions of (Channels, Height, Width)\n","transforms = {\n","    'none': v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True)\n","                        ]),\n","    'scale': v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True),\n","                        v2.Resize((resize_x, resize_y), antialias=True)\n","                        ]),\n","    'noise_gaussian': v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True),\n","                        v2.Lambda(lambda x: add_noise_gaussian(x))\n","                        ]),\n","    'noise_salt_pepper': v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True),\n","                        v2.Lambda(lambda x: add_noise_salt_pepper(x))\n","                        ]),\n","    'all_gaussian':     v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True),\n","                        v2.Resize((resize_x, resize_y), antialias=True),\n","                        v2.Lambda(lambda x: add_noise_gaussian(x))\n","                        ]),\n","    'all_salt_pepper':  v2.Compose([\n","                        v2.ToImage(), \n","                        v2.ToDtype(torch.float32, scale=True),\n","                        v2.Resize((resize_x, resize_y), antialias=True),\n","                        v2.Lambda(lambda x: add_noise_salt_pepper(x))\n","                        ])\n","}"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["from torch.utils.data import Dataset\n","from torchvision.transforms import v2\n","from PIL import Image\n","import os\n","\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.class_folders = os.listdir(root_dir)\n","        self.class_to_idx = {class_folder: i for i, class_folder in enumerate(self.class_folders)}\n","        self.images = self.make_dataset()\n","\n","    def make_dataset(self):\n","        images = []\n","        for class_folder in self.class_folders:\n","            class_path = os.path.join(self.root_dir, class_folder)\n","            for img_name in os.listdir(class_path):\n","                img_path = os.path.join(class_path, img_name)\n","                images.append((img_path, self.class_to_idx[class_folder]))\n","        return images\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.images[idx]\n","        image = Image.open(img_path)\n","\n","        random_number = self.random_gen.uniform(0, 1)\n","\n","        if self.transform:\n","            image = self.apply_random_transform(image, random_number)\n","\n","        return image, label\n","    \n","    def apply_random_transform(self, image, random_number):\n","        # Example: Apply different transformations based on the random number\n","        if random_number < 0.25:\n","            return transforms['noise_gaussian'](image)\n","        elif random_number < 0.5:\n","            return transforms['noise_salt_pepper'](image)\n","        else:\n","            return transforms['none'](image)\n","    "]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","transform = v2.Compose([\n","    v2.ToImage(), \n","    v2.ToDtype(torch.float32, scale=True)\n","])\n","\n","dataset = CustomDataset(root_dir='Dataset', transform=transform)\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"aB5UrJN0tB5D"},"source":["## Data normalization"]},{"cell_type":"markdown","metadata":{"id":"NciOQE4FtB5D"},"source":["# Architecture of the network"]},{"cell_type":"markdown","metadata":{},"source":["**CNN Model Creation**"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["class CustomCNN(nn.Module):\n","    def __init__(self, weights=\"DEFAULT\"):\n","        super(CustomCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  # MRI images are grayscale, so in_channels=1\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.fc1 = nn.Linear(128 * 8 * 8, 256)  # Adjust for the flattened conv3 output\n","        self.fc2 = nn.Linear(256, 4)  # 4 classes in our dataset\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = x.view(-1, 128 * 8 * 8)  # Flatten the tensor for the fully connected layer\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]}],"metadata":{"colab":{"collapsed_sections":["qNm0SENHtB4-"],"provenance":[]},"kernelspec":{"display_name":"ba-thesis","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
